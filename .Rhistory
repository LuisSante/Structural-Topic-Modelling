library(stm)
library(igraph)
library(stmCorrViz)
# Leer los datos
data <- read.csv("C:/Users/Usuario/Documents/Excelsius/word_count/out/model_yape_target.csv")
data$reviews <- as.character(data$reviews)
data$reviews[is.na(data$reviews)] <- ""
summary(data)
unique_value <- unique(data$label)
unique_value
length(unique_value)
data_negative <- subset(data, label == "Negativo")
data_negative
length(data_negative$label)
summary(data_negative)
data_negative_sorted <- data_negative[order(data_negative$appVersion), ]
row.names(data_negative_sorted) <- 1:nrow(data_negative_sorted)
head(data_negative_sorted)
unique_negative_value <- unique(data_negative$appVersion)
unique_negative_value
length(unique_negative_value)
sort_values_un <- sort(unique_negative_value)
sort_values_un
sort_values_un[2]
for (version in sort_values_un[2:length(sort_values_un)]) {
print(paste0("La version es ", version))
#version <- "1.1.0"
dir.create(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
setwd(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
new_data <- subset(data_negative_sorted, appVersion == version)
length(new_data$appVersion)
#new_data$label <- as.factor(new_data$label)
processed <- textProcessor(new_data$reviews, metadata=new_data)
processed$documents
# Preparar documentos para el modelo STM
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
docs
vocab <- out$vocab
vocab
meta <- out$meta
meta
if (length(docs) <= 5){
setwd("C:/Users/Usuario/Documents/RStudioCode/")
next
}
# Graficar palabras eliminadas según el umbral
pdf("stm-plot-removed.pdf", width=10, height=8.5)
plotRemoved(processed$documents, lower.thresh=seq(1, 200, by=100))
dev.off()
meta$at <- as.Date(meta$at)
meta$at <- as.numeric(meta$at)
meta$label <- as.factor(meta$label)
# Ajustar el modelo STM con 20 temas, incluyendo "label" como prevalencia
K <- max(3, min(20, length(vocab) - 1))
print(K)
stmFit <- stm(docs, vocab, K=K, prevalence=~s(at, df=5),
max.em.its=75, data=meta, init.type="Spectral", seed=8458159)
# Visualización básica del modelo
pdf("stm-plot-prevfit-summary.pdf", width=10, height=8.5)
plot(stmFit, type="summary", xlim=c(0, .4))
dev.off()
# Visualización de etiquetas para temas seleccionados
pdf("stm-plot-prevfit-labels.pdf", width=10, height=8.5)
plot(stmFit, type="labels", topics=c(3, 7, 20))
dev.off()
# Visualización de perspectivas entre dos temas
pdf("stm-plot-prevfit-perspectives.pdf", width=14, height=12.5)
plot(stmFit, type="perspectives", topics=c(7, 10))
dev.off()
# Identificar el número óptimo de temas (K)
kResult <- searchK(docs, vocab, K=c(7, 10, 15, 20), prevalence=~s(at, df=5), data=meta)
pdf("stm-plot-searchk.pdf", width=10, height=8.5)
plot(kResult)
dev.off()
# Analizar la calidad de los temas
pdf("stm-plot-topic-quality.pdf", width=10, height=8.5)
topicQuality(model=stmFit, documents=docs)
dev.off()
# Etiquetar temas
labelTopicsSel <- labelTopics(stmFit, c(3, 7, 20))
sink("stm-list-label-topics-selected.txt", append=FALSE, split=TRUE)
print(labelTopicsSel)
sink()
# Palabras clave con Sage Labels
sink("stm-list-sagelabel.txt", append=FALSE, split=TRUE)
print(sageLabels(stmFit))
sink()
# Estimar efectos de covariables, incluyendo comparación entre etiquetas
prep <- estimateEffect(1:20 ~ s(at), stmFit, meta=meta, uncertainty="Global")
pdf("stm-plot-estimate-effect.pdf", width=10, height=8.5)
plot(prep, covariate="at", topics=c(3, 7, 20), model=stmFit, method="continuous",
xlab="Time (at)", main="Effect of Time on Topics")
dev.off()
# Correlación entre temas
mod.out.corr <- topicCorr(stmFit)
pdf("stm-plot-topic-correlations.pdf", width=10, height=8.5)
plot(mod.out.corr)
dev.off()
setwd("C:/Users/Usuario/Documents/RStudioCode")
}
library(stm)
library(igraph)
library(stmCorrViz)
# Leer los datos
data <- read.csv("C:/Users/Usuario/Documents/Excelsius/word_count/out/model_yape_target.csv")
data$reviews <- as.character(data$reviews)
data$reviews[is.na(data$reviews)] <- ""
summary(data)
unique_value <- unique(data$label)
unique_value
length(unique_value)
data_negative <- subset(data, label == "Negativo")
data_negative
length(data_negative$label)
summary(data_negative)
data_negative_sorted <- data_negative[order(data_negative$appVersion), ]
row.names(data_negative_sorted) <- 1:nrow(data_negative_sorted)
head(data_negative_sorted)
unique_negative_value <- unique(data_negative$appVersion)
unique_negative_value
length(unique_negative_value)
sort_values_un <- sort(unique_negative_value)
head(sort_values_un)
sort_values_un[2]
for (version in sort_values_un[2:length(sort_values_un)]) {
print(paste0("La version es ", version))
#version <- "1.1.0"
dir.create(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
setwd(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
new_data <- subset(data_negative_sorted, appVersion == version)
length(new_data$appVersion)
#new_data$label <- as.factor(new_data$label)
processed <- textProcessor(new_data$reviews, metadata=new_data)
processed$documents
# Preparar documentos para el modelo STM
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
docs
vocab <- out$vocab
vocab
meta <- out$meta
meta
if (length(docs) <= 5){
setwd("C:/Users/Usuario/Documents/RStudioCode/")
next
}
# Graficar palabras eliminadas según el umbral
pdf("stm-plot-removed.pdf", width=10, height=8.5)
plotRemoved(processed$documents, lower.thresh=seq(1, 200, by=100))
dev.off()
meta$at <- as.Date(meta$at)
meta$at <- as.numeric(meta$at)
meta$label <- as.factor(meta$label)
# Ajustar el modelo STM con 20 temas, incluyendo "label" como prevalencia
K <- max(3, min(20, length(vocab) - 1))
print(K)
stmFit <- stm(docs, vocab, K=K, prevalence=~s(at, df=5),
max.em.its=75, data=meta, init.type="Spectral", seed=8458159)
# Visualización básica del modelo
pdf("stm-plot-prevfit-summary.pdf", width=10, height=8.5)
plot(stmFit, type="summary", xlim=c(0, .4))
dev.off()
# Visualización de etiquetas para temas seleccionados
pdf("stm-plot-prevfit-labels.pdf", width=10, height=8.5)
plot(stmFit, type="labels", topics=c(3, 7, 20))
dev.off()
# Visualización de perspectivas entre dos temas
pdf("stm-plot-prevfit-perspectives.pdf", width=14, height=12.5)
plot(stmFit, type="perspectives", topics=c(7, 10))
dev.off()
# Identificar el número óptimo de temas (K)
kResult <- searchK(docs, vocab, K=c(7, 10, 15, 20), prevalence=~s(at, df=5), data=meta)
pdf("stm-plot-searchk.pdf", width=10, height=8.5)
plot(kResult)
dev.off()
# Analizar la calidad de los temas
pdf("stm-plot-topic-quality.pdf", width=10, height=8.5)
topicQuality(model=stmFit, documents=docs)
dev.off()
# Etiquetar temas
labelTopicsSel <- labelTopics(stmFit, c(3, 7, 20))
sink("stm-list-label-topics-selected.txt", append=FALSE, split=TRUE)
print(labelTopicsSel)
sink()
# Palabras clave con Sage Labels
sink("stm-list-sagelabel.txt", append=FALSE, split=TRUE)
print(sageLabels(stmFit))
sink()
# Estimar efectos de covariables, incluyendo comparación entre etiquetas
prep <- estimateEffect(1:20 ~ s(at), stmFit, meta=meta, uncertainty="Global")
pdf("stm-plot-estimate-effect.pdf", width=10, height=8.5)
plot(prep, covariate="at", topics=c(3, 7, 20), model=stmFit, method="continuous",
xlab="Time (at)", main="Effect of Time on Topics")
dev.off()
# Correlación entre temas
mod.out.corr <- topicCorr(stmFit)
pdf("stm-plot-topic-correlations.pdf", width=10, height=8.5)
plot(mod.out.corr)
dev.off()
setwd("C:/Users/Usuario/Documents/RStudioCode")
}
library(stm)
library(igraph)
library(stmCorrViz)
# Leer los datos
data <- read.csv("C:/Users/Usuario/Documents/Excelsius/word_count/out/model_yape_target.csv")
data$reviews <- as.character(data$reviews)
data$reviews[is.na(data$reviews)] <- ""
summary(data)
unique_value <- unique(data$label)
unique_value
length(unique_value)
data_negative <- subset(data, label == "Negativo")
data_negative
length(data_negative$label)
summary(data_negative)
data_negative_sorted <- data_negative[order(data_negative$appVersion), ]
row.names(data_negative_sorted) <- 1:nrow(data_negative_sorted)
head(data_negative_sorted)
unique_negative_value <- unique(data_negative$appVersion)
unique_negative_value
length(unique_negative_value)
sort_values_un <- sort(unique_negative_value)
head(sort_values_un)
sort_values_un[2]
for (version in sort_values_un[2:length(sort_values_un)]) {
print(paste0("La version es ", version))
#version <- "1.1.0"
dir.create(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
setwd(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
new_data <- subset(data_negative_sorted, appVersion == version)
length(new_data$appVersion)
#new_data$label <- as.factor(new_data$label)
processed <- textProcessor(new_data$reviews, metadata=new_data)
processed$documents
# Preparar documentos para el modelo STM
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
docs
vocab <- out$vocab
vocab
meta <- out$meta
meta
if (length(docs) <= 5){
setwd("C:/Users/Usuario/Documents/RStudioCode/")
next
}
# Graficar palabras eliminadas según el umbral
pdf("stm-plot-removed.pdf", width=10, height=8.5)
plotRemoved(processed$documents, lower.thresh=seq(1, 200, by=100))
dev.off()
meta$at <- as.Date(meta$at)
meta$at <- as.numeric(meta$at)
meta$label <- as.factor(meta$label)
# Ajustar el modelo STM con 20 temas, incluyendo "label" como prevalencia
K <- max(3, min(20, length(vocab) - 1))
print(K)
stmFit <- stm(docs, vocab, K=K, prevalence=~s(at, df=5),
max.em.its=20, data=meta, init.type="Spectral", seed=8458159)
# Visualización básica del modelo
pdf("stm-plot-prevfit-summary.pdf", width=10, height=8.5)
plot(stmFit, type="summary", xlim=c(0, .4))
dev.off()
# Visualización de etiquetas para temas seleccionados
pdf("stm-plot-prevfit-labels.pdf", width=10, height=8.5)
plot(stmFit, type="labels", topics=c(3, 7, 20))
dev.off()
# Visualización de perspectivas entre dos temas
pdf("stm-plot-prevfit-perspectives.pdf", width=14, height=12.5)
plot(stmFit, type="perspectives", topics=c(7, 10))
dev.off()
# Identificar el número óptimo de temas (K)
kResult <- searchK(docs, vocab, K=c(7, 10, 15, 20), prevalence=~s(at, df=5), data=meta)
pdf("stm-plot-searchk.pdf", width=10, height=8.5)
plot(kResult)
dev.off()
# Analizar la calidad de los temas
pdf("stm-plot-topic-quality.pdf", width=10, height=8.5)
topicQuality(model=stmFit, documents=docs)
dev.off()
# Etiquetar temas
labelTopicsSel <- labelTopics(stmFit, c(3, 7, 20))
sink("stm-list-label-topics-selected.txt", append=FALSE, split=TRUE)
print(labelTopicsSel)
sink()
# Palabras clave con Sage Labels
sink("stm-list-sagelabel.txt", append=FALSE, split=TRUE)
print(sageLabels(stmFit))
sink()
# Estimar efectos de covariables, incluyendo comparación entre etiquetas
prep <- estimateEffect(1:20 ~ s(at), stmFit, meta=meta, uncertainty="Global")
pdf("stm-plot-estimate-effect.pdf", width=10, height=8.5)
plot(prep, covariate="at", topics=c(3, 7, 20), model=stmFit, method="continuous",
xlab="Time (at)", main="Effect of Time on Topics")
dev.off()
# Correlación entre temas
mod.out.corr <- topicCorr(stmFit)
pdf("stm-plot-topic-correlations.pdf", width=10, height=8.5)
plot(mod.out.corr)
dev.off()
setwd("C:/Users/Usuario/Documents/RStudioCode")
}
library(stm)
library(igraph)
library(stmCorrViz)
# Leer los datos
data <- read.csv("C:/Users/Usuario/Documents/Excelsius/word_count/out/model_yape_target.csv")
data$reviews <- as.character(data$reviews)
data$reviews[is.na(data$reviews)] <- ""
summary(data)
unique_value <- unique(data$label)
unique_value
length(unique_value)
data_negative <- subset(data, label == "Negativo")
data_negative
length(data_negative$label)
summary(data_negative)
data_negative_sorted <- data_negative[order(data_negative$appVersion), ]
row.names(data_negative_sorted) <- 1:nrow(data_negative_sorted)
head(data_negative_sorted)
unique_negative_value <- unique(data_negative$appVersion)
unique_negative_value
length(unique_negative_value)
sort_values_un <- sort(unique_negative_value)
head(sort_values_un)
sort_values_un[2]
for (version in sort_values_un[2:length(sort_values_un)]) {
print(paste0("La version es ", version))
#version <- "1.1.0"
dir.create(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
setwd(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
new_data <- subset(data_negative_sorted, appVersion == version)
length(new_data$appVersion)
#new_data$label <- as.factor(new_data$label)
processed <- textProcessor(new_data$reviews, metadata=new_data)
processed$documents
# Preparar documentos para el modelo STM
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
docs
vocab <- out$vocab
vocab
meta <- out$meta
meta
if (length(docs) <= 5){
setwd("C:/Users/Usuario/Documents/RStudioCode/")
next
}
# Graficar palabras eliminadas según el umbral
pdf("stm-plot-removed.pdf", width=10, height=8.5)
plotRemoved(processed$documents, lower.thresh=seq(1, 200, by=100))
dev.off()
meta$at <- as.Date(meta$at)
meta$at <- as.numeric(meta$at)
meta$label <- as.factor(meta$label)
# Ajustar el modelo STM con 20 temas, incluyendo "label" como prevalencia
K <- max(3, min(20, length(vocab) - 1))
print(K)
stmFit <- stm(docs, vocab, K=K, prevalence=~s(at, df=5),
max.em.its=20, data=meta, init.type="Spectral", seed=8458159)
# Visualización básica del modelo
pdf("stm-plot-prevfit-summary.pdf", width=10, height=8.5)
plot(stmFit, type="summary", xlim=c(0, .4))
dev.off()
# Visualización de etiquetas para temas seleccionados
pdf("stm-plot-prevfit-labels.pdf", width=10, height=8.5)
plot(stmFit, type="labels", topics=c(3, 7, 20))
dev.off()
# Visualización de perspectivas entre dos temas
pdf("stm-plot-prevfit-perspectives.pdf", width=14, height=12.5)
plot(stmFit, type="perspectives", topics=c(7, 10))
dev.off()
# Identificar el número óptimo de temas (K)
kResult <- searchK(docs, vocab, K=c(7, 10, 15, 20), prevalence=~s(at, df=5), data=meta)
pdf("stm-plot-searchk.pdf", width=10, height=8.5)
plot(kResult)
dev.off()
# Analizar la calidad de los temas
pdf("stm-plot-topic-quality.pdf", width=10, height=8.5)
topicQuality(model=stmFit, documents=docs)
dev.off()
# Etiquetar temas
labelTopicsSel <- labelTopics(stmFit, c(3, 7, 20))
sink("stm-list-label-topics-selected.txt", append=FALSE, split=TRUE)
print(labelTopicsSel)
sink()
# Palabras clave con Sage Labels
sink("stm-list-sagelabel.txt", append=FALSE, split=TRUE)
print(sageLabels(stmFit))
sink()
# Estimar efectos de covariables, incluyendo comparación entre etiquetas
prep <- estimateEffect(1:20 ~ s(at), stmFit, meta=meta, uncertainty="Global")
pdf("stm-plot-estimate-effect.pdf", width=10, height=8.5)
plot(prep, covariate="at", topics=c(3, 7, 20), model=stmFit, method="continuous",
xlab="Time (at)", main="Effect of Time on Topics")
dev.off()
# Correlación entre temas
mod.out.corr <- topicCorr(stmFit)
pdf("stm-plot-topic-correlations.pdf", width=10, height=8.5)
plot(mod.out.corr)
dev.off()
setwd("C:/Users/Usuario/Documents/RStudioCode")
}
library(stm)
library(igraph)
library(stmCorrViz)
# Leer los datos
data <- read.csv("C:/Users/Usuario/Documents/Excelsius/word_count/out/model_yape_target.csv")
data$reviews <- as.character(data$reviews)
data$reviews[is.na(data$reviews)] <- ""
summary(data)
unique_value <- unique(data$label)
unique_value
length(unique_value)
data_negative <- subset(data, label == "Negativo")
head(data_negative)
length(data_negative$label)
summary(data_negative)
data_negative_sorted <- data_negative[order(data_negative$appVersion), ]
row.names(data_negative_sorted) <- 1:nrow(data_negative_sorted)
head(data_negative_sorted)
unique_negative_value <- unique(data_negative$appVersion)
unique_negative_value
length(unique_negative_value)
sort_values_un <- sort(unique_negative_value)
head(sort_values_un)
sort_values_un[2]
for (version in sort_values_un[2:length(sort_values_un)]) {
print(paste0("La version es ", version))
#version <- "1.1.0"
dir.create(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
setwd(paste0("C:/Users/Usuario/Documents/RStudioCode/", version))
new_data <- subset(data_negative_sorted, appVersion == version)
length(new_data$appVersion)
#new_data$label <- as.factor(new_data$label)
processed <- textProcessor(new_data$reviews, metadata=new_data)
processed$documents
# Preparar documentos para el modelo STM
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
docs
vocab <- out$vocab
vocab
meta <- out$meta
meta
if (length(docs) <= 5){
setwd("C:/Users/Usuario/Documents/RStudioCode/")
next
}
# Graficar palabras eliminadas según el umbral
pdf("stm-plot-removed.pdf", width=10, height=8.5)
plotRemoved(processed$documents, lower.thresh=seq(1, 200, by=100))
dev.off()
meta$at <- as.Date(meta$at)
meta$at <- as.numeric(meta$at)
meta$label <- as.factor(meta$label)
# Ajustar el modelo STM con 20 temas, incluyendo "label" como prevalencia
K <- max(3, min(20, length(vocab) - 1))
print(K)
stmFit <- stm(docs, vocab, K=K, prevalence=~s(at, df=5),
max.em.its=20, data=meta, init.type="Spectral", seed=8458159)
# Visualización básica del modelo
pdf("stm-plot-prevfit-summary.pdf", width=10, height=8.5)
plot(stmFit, type="summary", xlim=c(0, .4))
dev.off()
# Visualización de etiquetas para temas seleccionados
pdf("stm-plot-prevfit-labels.pdf", width=10, height=8.5)
plot(stmFit, type="labels", topics=c(3, 7, 20))
dev.off()
# Visualización de perspectivas entre dos temas
pdf("stm-plot-prevfit-perspectives.pdf", width=14, height=12.5)
plot(stmFit, type="perspectives", topics=c(7, 10))
dev.off()
# Identificar el número óptimo de temas (K)
kResult <- searchK(docs, vocab, K=c(7, 10, 15, 20), prevalence=~s(at, df=5), data=meta)
pdf("stm-plot-searchk.pdf", width=10, height=8.5)
plot(kResult)
dev.off()
# Analizar la calidad de los temas
pdf("stm-plot-topic-quality.pdf", width=10, height=8.5)
topicQuality(model=stmFit, documents=docs)
dev.off()
# Etiquetar temas
labelTopicsSel <- labelTopics(stmFit, c(3, 7, 20))
sink("stm-list-label-topics-selected.txt", append=FALSE, split=TRUE)
print(labelTopicsSel)
sink()
# Palabras clave con Sage Labels
sink("stm-list-sagelabel.txt", append=FALSE, split=TRUE)
print(sageLabels(stmFit))
sink()
# Estimar efectos de covariables, incluyendo comparación entre etiquetas
prep <- estimateEffect(1:20 ~ s(at), stmFit, meta=meta, uncertainty="Global")
pdf("stm-plot-estimate-effect.pdf", width=10, height=8.5)
plot(prep, covariate="at", topics=c(3, 7, 20), model=stmFit, method="continuous",
xlab="Time (at)", main="Effect of Time on Topics")
dev.off()
# Correlación entre temas
mod.out.corr <- topicCorr(stmFit)
pdf("stm-plot-topic-correlations.pdf", width=10, height=8.5)
plot(mod.out.corr)
dev.off()
setwd("C:/Users/Usuario/Documents/RStudioCode")
}
rm(list = ls())
setwd("C:/Users/Usuario/Documents/RStudioCode")
